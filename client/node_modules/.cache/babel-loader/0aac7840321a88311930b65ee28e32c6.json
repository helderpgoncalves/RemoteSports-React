{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Softmax, util } from '@tensorflow/tfjs-core';\nimport { exp } from './Exp';\nimport { max } from './Max';\nimport { realDiv } from './RealDiv';\nimport { reshape } from './Reshape';\nimport { sub } from './Sub';\nimport { sum } from './Sum';\nexport function softmax(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    logits\n  } = inputs;\n  const {\n    dim\n  } = attrs;\n  const axes = util.parseAxisParam([dim], logits.shape);\n  const maxLogit = max({\n    inputs: {\n      x: logits\n    },\n    backend,\n    attrs: {\n      reductionIndices: axes,\n      keepDims: false\n    }\n  });\n  const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n  const maxLogitsReshaped = reshape({\n    inputs: {\n      x: maxLogit\n    },\n    backend,\n    attrs: {\n      shape: expandedShape\n    }\n  });\n  const a = sub({\n    inputs: {\n      a: logits,\n      b: maxLogitsReshaped\n    },\n    backend\n  });\n  const b = exp({\n    inputs: {\n      x: a\n    },\n    backend\n  });\n  const sumExp = sum({\n    inputs: {\n      x: b\n    },\n    backend,\n    attrs: {\n      axis: axes,\n      keepDims: false\n    }\n  });\n  const sumExpReshaped = reshape({\n    inputs: {\n      x: sumExp\n    },\n    backend,\n    attrs: {\n      shape: expandedShape\n    }\n  });\n  const res = realDiv({\n    inputs: {\n      a: b,\n      b: sumExpReshaped\n    },\n    backend\n  });\n  backend.disposeIntermediateTensorInfo(maxLogit);\n  backend.disposeIntermediateTensorInfo(maxLogitsReshaped);\n  backend.disposeIntermediateTensorInfo(a);\n  backend.disposeIntermediateTensorInfo(b);\n  backend.disposeIntermediateTensorInfo(sumExp);\n  backend.disposeIntermediateTensorInfo(sumExpReshaped);\n  return res;\n}\nexport const softmaxConfig = {\n  kernelName: Softmax,\n  backendName: 'webgl',\n  kernelFunc: softmax\n};","map":{"version":3,"sources":["../../src/kernels/Softmax.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,YAAR,EAAgD,OAAhD,EAAkG,IAAlG,QAA6G,uBAA7G;AAIA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AAEA,OAAM,SAAU,OAAV,CAAkB,IAAlB,EAIL;AACC,QAAM;AAAC,IAAA,MAAD;AAAS,IAAA,OAAT;AAAkB,IAAA;AAAlB,MAA2B,IAAjC;AACA,QAAM;AAAC,IAAA;AAAD,MAAW,MAAjB;AACA,QAAM;AAAC,IAAA;AAAD,MAAQ,KAAd;AAEA,QAAM,IAAI,GAAG,IAAI,CAAC,cAAL,CAAoB,CAAC,GAAD,CAApB,EAA2B,MAAM,CAAC,KAAlC,CAAb;AAEA,QAAM,QAAQ,GAAG,GAAG,CAAC;AACnB,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KADW;AAEnB,IAAA,OAFmB;AAGnB,IAAA,KAAK,EAAE;AAAC,MAAA,gBAAgB,EAAE,IAAnB;AAAyB,MAAA,QAAQ,EAAE;AAAnC;AAHY,GAAD,CAApB;AAMA,QAAM,aAAa,GAAG,YAAY,CAAC,oBAAb,CAAkC,QAAQ,CAAC,KAA3C,EAAkD,IAAlD,CAAtB;AAEA,QAAM,iBAAiB,GACnB,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAwB,IAAA,OAAxB;AAAiC,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE;AAAR;AAAxC,GAAD,CADX;AAEA,QAAM,CAAC,GACH,GAAG,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE,MAAJ;AAAY,MAAA,CAAC,EAAE;AAAf,KAAT;AAA4C,IAAA;AAA5C,GAAD,CADP;AAEA,QAAM,CAAC,GAAG,GAAG,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAiB,IAAA;AAAjB,GAAD,CAAb;AACA,QAAM,MAAM,GACR,GAAG,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAiB,IAAA,OAAjB;AAA0B,IAAA,KAAK,EAAE;AAAC,MAAA,IAAI,EAAE,IAAP;AAAa,MAAA,QAAQ,EAAE;AAAvB;AAAjC,GAAD,CADP;AAEA,QAAM,cAAc,GAChB,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE;AAAJ,KAAT;AAAsB,IAAA,OAAtB;AAA+B,IAAA,KAAK,EAAE;AAAC,MAAA,KAAK,EAAE;AAAR;AAAtC,GAAD,CADX;AAGA,QAAM,GAAG,GACL,OAAO,CAAC;AAAC,IAAA,MAAM,EAAE;AAAC,MAAA,CAAC,EAAE,CAAJ;AAAO,MAAA,CAAC,EAAE;AAAV,KAAT;AAAoC,IAAA;AAApC,GAAD,CADX;AAGA,EAAA,OAAO,CAAC,6BAAR,CAAsC,QAAtC;AACA,EAAA,OAAO,CAAC,6BAAR,CAAsC,iBAAtC;AACA,EAAA,OAAO,CAAC,6BAAR,CAAsC,CAAtC;AACA,EAAA,OAAO,CAAC,6BAAR,CAAsC,CAAtC;AACA,EAAA,OAAO,CAAC,6BAAR,CAAsC,MAAtC;AACA,EAAA,OAAO,CAAC,6BAAR,CAAsC,cAAtC;AAEA,SAAO,GAAP;AACD;AAED,OAAO,MAAM,aAAa,GAAiB;AACzC,EAAA,UAAU,EAAE,OAD6B;AAEzC,EAAA,WAAW,EAAE,OAF4B;AAGzC,EAAA,UAAU,EAAE;AAH6B,CAApC","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Softmax, util } from '@tensorflow/tfjs-core';\nimport { exp } from './Exp';\nimport { max } from './Max';\nimport { realDiv } from './RealDiv';\nimport { reshape } from './Reshape';\nimport { sub } from './Sub';\nimport { sum } from './Sum';\nexport function softmax(args) {\n    const { inputs, backend, attrs } = args;\n    const { logits } = inputs;\n    const { dim } = attrs;\n    const axes = util.parseAxisParam([dim], logits.shape);\n    const maxLogit = max({\n        inputs: { x: logits },\n        backend,\n        attrs: { reductionIndices: axes, keepDims: false }\n    });\n    const expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n    const maxLogitsReshaped = reshape({ inputs: { x: maxLogit }, backend, attrs: { shape: expandedShape } });\n    const a = sub({ inputs: { a: logits, b: maxLogitsReshaped }, backend });\n    const b = exp({ inputs: { x: a }, backend });\n    const sumExp = sum({ inputs: { x: b }, backend, attrs: { axis: axes, keepDims: false } });\n    const sumExpReshaped = reshape({ inputs: { x: sumExp }, backend, attrs: { shape: expandedShape } });\n    const res = realDiv({ inputs: { a: b, b: sumExpReshaped }, backend });\n    backend.disposeIntermediateTensorInfo(maxLogit);\n    backend.disposeIntermediateTensorInfo(maxLogitsReshaped);\n    backend.disposeIntermediateTensorInfo(a);\n    backend.disposeIntermediateTensorInfo(b);\n    backend.disposeIntermediateTensorInfo(sumExp);\n    backend.disposeIntermediateTensorInfo(sumExpReshaped);\n    return res;\n}\nexport const softmaxConfig = {\n    kernelName: Softmax,\n    backendName: 'webgl',\n    kernelFunc: softmax\n};\n//# sourceMappingURL=Softmax.js.map"]},"metadata":{},"sourceType":"module"}