{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\n * @deprecated\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\n\nfunction addStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'addStrict');\n  const $b = convertToTensor(b, 'b', 'addStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n  return add($a, $b);\n}\n/**\n * @deprecated\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\n\n\nfunction subStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'subStrict');\n  const $b = convertToTensor(b, 'b', 'subStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n  return sub($a, $b);\n}\n/**\n * @deprecated\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\n\n\nfunction powStrict_(base, exp) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n  return pow(base, exp);\n}\n/**\n * @deprecated\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\n\n\nfunction mulStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'mul');\n  const $b = convertToTensor(b, 'b', 'mul');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n  return mul($a, $b);\n}\n/**\n * @deprecated\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\n\n\nfunction divStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'div');\n  const $b = convertToTensor(b, 'b', 'div');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n  return div($a, $b);\n}\n/**\n * @deprecated\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\n\n\nfunction modStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'modStrict');\n  const $b = convertToTensor(b, 'b', 'modStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n  return mod($a, $b);\n}\n/**\n * @deprecated\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\n\n\nfunction minimumStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'minimumStrict');\n  const $b = convertToTensor(b, 'b', 'minimumStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n  return minimum($a, $b);\n}\n/**\n * @deprecated\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\n\n\nfunction maximumStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'maximumStrict');\n  const $b = convertToTensor(b, 'b', 'maximumStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n  return maximum($a, $b);\n}\n/**\n * @deprecated\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\n\n\nfunction squaredDifferenceStrict_(a, b) {\n  deprecationWarn('strict variants of ops have been deprecated ' + 'and will be removed in future');\n  const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n  const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n  util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n  return squaredDifference($a, $b);\n}\n\nexport const addStrict = op({\n  addStrict_\n});\nexport const divStrict = op({\n  divStrict_\n});\nexport const maximumStrict = op({\n  maximumStrict_\n});\nexport const minimumStrict = op({\n  minimumStrict_\n});\nexport const modStrict = op({\n  modStrict_\n});\nexport const mulStrict = op({\n  mulStrict_\n});\nexport const powStrict = op({\n  powStrict_\n});\nexport const squaredDifferenceStrict = op({\n  squaredDifferenceStrict_\n});\nexport const subStrict = op({\n  subStrict_\n});","map":{"version":3,"sources":["../../src/ops/binary_ops.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;AAeG;AAEH,SAAQ,eAAR,QAA8B,YAA9B;AAEA,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,OAAO,KAAK,IAAZ,MAAsB,SAAtB;AAEA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,OAAR,QAAsB,WAAtB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,GAAR,QAAkB,OAAlB;AACA,SAAQ,iBAAR,QAAgC,sBAAhC;AACA,SAAQ,GAAR,QAAkB,OAAlB;AAEA;;;;;;;;AAQG;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAGA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,sBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,sBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,UAAT,CAAsC,IAAtC,EAA+C,GAA/C,EAA0D;AACxD,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,EAAA,IAAI,CAAC,iBAAL,CAAuB,IAAI,CAAC,KAA5B,EAAmC,GAAG,CAAC,KAAvC,EAA8C,sBAA9C;AACA,SAAO,GAAG,CAAC,IAAD,EAAO,GAAP,CAAV;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,2BAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,KAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,yBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,UAAT,CAAsC,CAAtC,EAAuD,CAAvD,EAAsE;AACpE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,sBAA3C;AACA,SAAO,GAAG,CAAC,EAAD,EAAK,EAAL,CAAV;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,cAAT,CAA0C,CAA1C,EAA2D,CAA3D,EAA0E;AACxE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,0BAA3C;AACA,SAAO,OAAO,CAAC,EAAD,EAAK,EAAL,CAAd;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,cAAT,CAA0C,CAA1C,EAA2D,CAA3D,EAA0E;AACxE,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAIA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,eAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CAAuB,EAAE,CAAC,KAA1B,EAAiC,EAAE,CAAC,KAApC,EAA2C,0BAA3C;AACA,SAAO,OAAO,CAAC,EAAD,EAAK,EAAL,CAAd;AACD;AAED;;;;;;;;;AASG;;;AACH,SAAS,wBAAT,CACI,CADJ,EACqB,CADrB,EACoC;AAClC,EAAA,eAAe,CACX,iDACA,+BAFW,CAAf;AAGA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,yBAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,yBAAT,CAA1B;AACA,EAAA,IAAI,CAAC,iBAAL,CACI,EAAE,CAAC,KADP,EACc,EAAE,CAAC,KADjB,EACwB,oCADxB;AAEA,SAAO,iBAAiB,CAAC,EAAD,EAAK,EAAL,CAAxB;AACD;;AAED,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB;AACP,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB;AACP,OAAO,MAAM,aAAa,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAxB;AACP,OAAO,MAAM,aAAa,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAxB;AACP,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB;AACP,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB;AACP,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB;AACP,OAAO,MAAM,uBAAuB,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAlC;AACP,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { deprecationWarn } from '../globals';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { maximum } from './maximum';\nimport { minimum } from './minimum';\nimport { mod } from './mod';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { squaredDifference } from './squared_difference';\nimport { sub } from './sub';\n/**\n * @deprecated\n * Adds two `tf.Tensor`s element-wise, A + B.\n *\n * Inputs must be the same shape. For broadcasting support, use add() instead.\n *\n * @param a The first Tensor to add element-wise.\n * @param b The second Tensor to add element-wise.\n */\nfunction addStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'addStrict');\n    const $b = convertToTensor(b, 'b', 'addStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in addStrict: ');\n    return add($a, $b);\n}\n/**\n * @deprecated\n * Subtracts two `tf.Tensor`s element-wise, A - B. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.sub` instead.\n *\n * @param a The first Tensor to subtract element-wise.\n * @param b The second Tensor to subtract element-wise.\n */\nfunction subStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'subStrict');\n    const $b = convertToTensor(b, 'b', 'subStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in subStrict: ');\n    return sub($a, $b);\n}\n/**\n * @deprecated\n * Computes the power of one `tf.Tensor` to another. Inputs must\n * be the same shape.\n *\n * For broadcasting support, use `tf.pow` instead.\n *\n * @param base The base tensor to pow element-wise.\n * @param exp The exponent tensor to pow element-wise.\n */\nfunction powStrict_(base, exp) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    util.assertShapesMatch(base.shape, exp.shape, 'Error in powStrict: ');\n    return pow(base, exp);\n}\n/**\n * @deprecated\n * Multiplies two `tf.Tensor`s element-wise, A * B.\n *\n * Inputs must be the same shape. For broadcasting support, use `tf.mul`.\n *\n * @param a The first tensor to multiply.\n * @param b The first tensor to multiply. Must have the same\n *    dtype as `a`.\n */\nfunction mulStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'mul');\n    const $b = convertToTensor(b, 'b', 'mul');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in multiplyStrict: ');\n    return mul($a, $b);\n}\n/**\n * @deprecated\n * Divides two `tf.Tensor`s element-wise, A / B. Inputs must\n * be the same shape.\n *\n * @param a The first tensor as the numerator for element-wise division.\n * @param b The second tensor as the denominator for element-wise division.\n */\nfunction divStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'div');\n    const $b = convertToTensor(b, 'b', 'div');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in divideStrict: ');\n    return div($a, $b);\n}\n/**\n * @deprecated\n * Returns the mod of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use mod().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction modStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'modStrict');\n    const $b = convertToTensor(b, 'b', 'modStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in modStrict: ');\n    return mod($a, $b);\n}\n/**\n * @deprecated\n * Returns the min of a and b (`a < b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use minimum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction minimumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'minimumStrict');\n    const $b = convertToTensor(b, 'b', 'minimumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in minimumStrict: ');\n    return minimum($a, $b);\n}\n/**\n * @deprecated\n * Returns the max of a and b (`a > b ? a : b`) element-wise. Inputs must\n * be the same shape. For broadcasting support, use maximum().\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n */\nfunction maximumStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'maximumStrict');\n    const $b = convertToTensor(b, 'b', 'maximumStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in maximumStrict: ');\n    return maximum($a, $b);\n}\n/**\n * @deprecated\n * Returns (a - b) * (a - b) element-wise.\n *\n * Inputs must be the same shape. For broadcasting support, use\n * `tf.squaredDifference` instead.\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same type as `a`.\n */\nfunction squaredDifferenceStrict_(a, b) {\n    deprecationWarn('strict variants of ops have been deprecated ' +\n        'and will be removed in future');\n    const $a = convertToTensor(a, 'a', 'squaredDifferenceStrict');\n    const $b = convertToTensor(b, 'b', 'squaredDifferenceStrict');\n    util.assertShapesMatch($a.shape, $b.shape, 'Error in squaredDifferenceStrict: ');\n    return squaredDifference($a, $b);\n}\nexport const addStrict = op({ addStrict_ });\nexport const divStrict = op({ divStrict_ });\nexport const maximumStrict = op({ maximumStrict_ });\nexport const minimumStrict = op({ minimumStrict_ });\nexport const modStrict = op({ modStrict_ });\nexport const mulStrict = op({ mulStrict_ });\nexport const powStrict = op({ powStrict_ });\nexport const squaredDifferenceStrict = op({ squaredDifferenceStrict_ });\nexport const subStrict = op({ subStrict_ });\n//# sourceMappingURL=binary_ops.js.map"]},"metadata":{},"sourceType":"module"}